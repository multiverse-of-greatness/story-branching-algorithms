import random
import uuid

import ujson
from loguru import logger

from src.algorithms.core import get_prompts_by_branching_type
from src.models.enums.branching_type import BranchingType
from src.models.frontier_item import FrontierItem
from src.models.generation_context import GenerationContext
from src.models.story.story_choice import StoryChoice
from src.models.story_branch import StoryBranch
from src.models.story_chunk import StoryChunk
from src.models.story_data import StoryData
from src.types.openai import ConversationHistory
from src.utils.openai_ai import append_openai_message


def process_generation_queue(ctx: GenerationContext, story_data: StoryData):
    cnt = 0
    frontiers = ctx.get_frontiers()
    while len(ctx.get_frontiers()) > 0:
        cnt += 1
        item = frontiers.pop(0)

        current_num_choices = random.randint(ctx.config.min_num_choices, ctx.config.max_num_choices)
        history: ConversationHistory = ctx.get_initial_history() if item.parent_chunk is None else ujson.loads(item.parent_chunk.history)

        prompt = get_prompts_by_branching_type(item.choice, ctx, item.current_chapter, current_num_choices, item.parent_chunk, item.state,
                                               story_data, item.used_choice_opportunity)

        logger.debug(f"Current frontier item: {item}")

        history = append_openai_message(prompt, history=history)

        # Retry chunk generation if failed
        max_retry_attempts = 3
        has_chunk_generation_success, current_attempt = False, 0
        current_chunk, story_chunk_raw, choices = None, None, None
        while not has_chunk_generation_success and current_attempt < max_retry_attempts:
            try:
                story_chunk_raw, story_chunk_obj = ctx.generation_model.generate_content(ctx, history)
                story_chunk_obj["id"] = str(uuid.uuid1())
                story_chunk_obj["chapter"] = item.current_chapter
                story_chunk_obj["story_id"] = ctx.story_id
                story_chunk_obj["num_opportunities"] = item.used_choice_opportunity
                current_chunk = StoryChunk.from_dict(story_chunk_obj)
                choices = [StoryChoice.from_dict(c) for c in story_chunk_obj.get("choices", [])]
                has_chunk_generation_success = True
            except Exception as e:
                current_attempt += 1
                logger.warning(f"Exception occurred while chat completion: {e}")

        if not has_chunk_generation_success or current_chunk is None or story_chunk_raw is None:
            logger.error(f"Failed to generate story chunk.")
            logger.error(f"Story ID: {ctx.story_id}, Frontier Item: {item}")
            logger.error("Exiting...")
            exit(1)

        current_chunk.history = ujson.dumps(append_openai_message(story_chunk_raw, role="assistant", history=history))

        if len(current_chunk.story) == 0:
            logger.warning(f"Story chunk {current_chunk.id} has no story narratives.")

        # Save to DB
        ctx.repository.create_story_chunk(current_chunk)
        if item.parent_chunk is None:
            ctx.repository.set_start_chunk(ctx.story_id, current_chunk.id)
        else:
            ctx.repository.create_branch(StoryBranch(
                source_chunk_id=item.parent_chunk.id,
                target_chunk_id=current_chunk.id,
                choice=item.choice
            ))

        child_chunks: list[FrontierItem] = []
        if item.state is BranchingType.BRANCHING:
            if item.used_choice_opportunity < ctx.config.max_num_choices_opportunity:  # Branch to multiple choices
                if len(choices) != current_num_choices:
                    logger.warning(f"Choices generated by model ({len(choices)}) not equal to setting "
                                   f"choices ({current_num_choices})")
                for choice in choices:
                    child_chunks.append(FrontierItem(item.current_chapter, item.used_choice_opportunity + 1, current_chunk, choice, BranchingType.BRANCHING))
            elif item.used_choice_opportunity == ctx.config.max_num_choices_opportunity:
                if item.current_chapter < ctx.config.num_chapters:  # Branch to the end of chapter
                    child_chunks.append(FrontierItem(item.current_chapter, item.used_choice_opportunity, current_chunk, None, BranchingType.CHAPTER_END))
                elif item.current_chapter == ctx.config.num_chapters:  # Branch to the end of game
                    child_chunks.append(FrontierItem(item.current_chapter, item.used_choice_opportunity, current_chunk, None, BranchingType.GAME_END))
        elif item.state is BranchingType.CHAPTER_END:
            if item.current_chapter < ctx.config.num_chapters:  # Branch to the next chapter
                child_chunks.append(FrontierItem(item.current_chapter + 1, 0, current_chunk, None, BranchingType.BRANCHING))

        frontiers.extend(child_chunks)
        ctx.set_frontiers(frontiers)

    ctx.completed()
    logger.debug(f"Total number of chunks: {cnt}")
    logger.debug(f"End of story generation for story ID: {ctx.story_id}")
